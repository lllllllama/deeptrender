#!/usr/bin/env python
"""
å…³é”®è¯æå–å®Œæ•´éªŒæ”¶è„šæœ¬

éªŒæ”¶é¡¹ç›®ï¼š
A. è¦†ç›–ç‡ï¼ˆCoverageï¼‰
B. æ¯ç¯‡å…³é”®è¯æ•°é‡åˆ†å¸ƒï¼ˆQuantityï¼‰
C. å™ªå£°ç‡ï¼ˆNoiseï¼‰
D. åˆ†æ•°å¥åº·ï¼ˆScore Sanityï¼‰
E. å¹‚ç­‰æ€§ï¼ˆIdempotencyï¼‰
"""
import sqlite3
import sys
from pathlib import Path
from collections import Counter

sys.path.insert(0, str(Path(__file__).parent))
from config import DATABASE_PATH
from extractor.keyword_filter import BANNED_WORDS, ENGLISH_STOPWORDS, DOMAIN_NOISE_WORDS


def main():
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    
    print("=" * 70)
    print("ğŸ“Š å…³é”®è¯æå–å®Œæ•´éªŒæ”¶æŠ¥å‘Š")
    print("=" * 70)
    
    # ========================================
    # éªŒæ”¶ Aï¼šè¦†ç›–ç‡
    # ========================================
    print("\n" + "-" * 70)
    print("A. è¦†ç›–ç‡ï¼ˆCoverageï¼‰")
    print("-" * 70)
    
    # æœ‰æ‘˜è¦çš„è®ºæ–‡æ•°
    cur = conn.execute("""
        SELECT COUNT(*) FROM papers 
        WHERE abstract IS NOT NULL AND abstract != ''
    """)
    papers_with_abstract = cur.fetchone()[0]
    
    # æœ‰ YAKE å…³é”®è¯çš„è®ºæ–‡æ•°
    cur = conn.execute("""
        SELECT COUNT(DISTINCT paper_id) FROM paper_keywords WHERE method = 'yake'
    """)
    papers_with_yake = cur.fetchone()[0]
    
    coverage = papers_with_yake / papers_with_abstract * 100 if papers_with_abstract else 0
    print(f"   æœ‰æ‘˜è¦çš„è®ºæ–‡: {papers_with_abstract}")
    print(f"   å·²æå– YAKE å…³é”®è¯: {papers_with_yake}")
    print(f"   è¦†ç›–ç‡: {coverage:.1f}% {'âœ…' if coverage >= 95 else 'âš ï¸'}")
    
    # ========================================
    # éªŒæ”¶ Bï¼šæ¯ç¯‡å…³é”®è¯æ•°é‡åˆ†å¸ƒ
    # ========================================
    print("\n" + "-" * 70)
    print("B. æ¯ç¯‡å…³é”®è¯æ•°é‡åˆ†å¸ƒï¼ˆQuantityï¼‰")
    print("-" * 70)
    
    cur = conn.execute("""
        SELECT paper_id, COUNT(*) as kw_count
        FROM paper_keywords WHERE method = 'yake'
        GROUP BY paper_id
    """)
    counts = [r["kw_count"] for r in cur.fetchall()]
    
    if counts:
        avg_count = sum(counts) / len(counts)
        min_count = min(counts)
        max_count = max(counts)
        zero_count = sum(1 for c in counts if c == 0)
        
        print(f"   å¹³å‡æ¯ç¯‡å…³é”®è¯æ•°: {avg_count:.1f} {'âœ…' if 10 <= avg_count <= 20 else 'âš ï¸'}")
        print(f"   èŒƒå›´: [{min_count}, {max_count}]")
        print(f"   å…³é”®è¯ä¸º 0 çš„è®ºæ–‡: {zero_count} ({zero_count/len(counts)*100:.1f}%)")
        
        # åˆ†å¸ƒç›´æ–¹å›¾
        bins = Counter()
        for c in counts:
            if c <= 5:
                bins["0-5"] += 1
            elif c <= 10:
                bins["6-10"] += 1
            elif c <= 15:
                bins["11-15"] += 1
            else:
                bins["16+"] += 1
        
        print("   åˆ†å¸ƒ:")
        for bin_name in ["0-5", "6-10", "11-15", "16+"]:
            pct = bins[bin_name] / len(counts) * 100
            print(f"      {bin_name}: {bins[bin_name]} ({pct:.1f}%)")
    
    # ========================================
    # éªŒæ”¶ Cï¼šå™ªå£°ç‡
    # ========================================
    print("\n" + "-" * 70)
    print("C. å™ªå£°ç‡ï¼ˆNoiseï¼‰")
    print("-" * 70)
    
    # è·å– Top-50 å…³é”®è¯
    cur = conn.execute("""
        SELECT keyword, COUNT(*) as cnt
        FROM paper_keywords WHERE method = 'yake'
        GROUP BY keyword
        ORDER BY cnt DESC
        LIMIT 50
    """)
    top_keywords = [(r["keyword"], r["cnt"]) for r in cur.fetchall()]
    
    all_noise = BANNED_WORDS | ENGLISH_STOPWORDS | DOMAIN_NOISE_WORDS
    
    noise_count = 0
    noise_keywords = []
    for kw, cnt in top_keywords:
        if kw in all_noise:
            noise_count += 1
            noise_keywords.append(kw)
    
    noise_rate = noise_count / len(top_keywords) * 100 if top_keywords else 0
    print(f"   Top-50 ä¸­å™ªå£°è¯æ•°: {noise_count}")
    print(f"   å™ªå£°ç‡: {noise_rate:.1f}% {'âœ…' if noise_rate < 10 else 'âŒ'}")
    
    if noise_keywords:
        print(f"   å™ªå£°è¯: {', '.join(noise_keywords[:10])}")
    
    print("\n   Top-20 å…³é”®è¯:")
    for kw, cnt in top_keywords[:20]:
        marker = "âš ï¸" if kw in all_noise else ""
        print(f"      [{cnt:3d}] {kw} {marker}")
    
    # æ£€æŸ¥çº¯æ•°å­—/ç¬¦å·
    cur = conn.execute("""
        SELECT keyword FROM paper_keywords WHERE method = 'yake'
    """)
    all_keywords = [r["keyword"] for r in cur.fetchall()]
    
    import re
    numeric_keywords = [kw for kw in all_keywords if re.match(r'^[\d\s.,%-]+$', kw)]
    numeric_rate = len(numeric_keywords) / len(all_keywords) * 100 if all_keywords else 0
    print(f"\n   çº¯æ•°å­—/ç¬¦å·å…³é”®è¯: {len(numeric_keywords)} ({numeric_rate:.2f}%) {'âœ…' if numeric_rate < 1 else 'âš ï¸'}")
    
    # ========================================
    # éªŒæ”¶ Dï¼šåˆ†æ•°å¥åº·
    # ========================================
    print("\n" + "-" * 70)
    print("D. åˆ†æ•°å¥åº·ï¼ˆScore Sanityï¼‰")
    print("-" * 70)
    
    cur = conn.execute("""
        SELECT MIN(score) as min_s, MAX(score) as max_s, AVG(score) as avg_s
        FROM paper_keywords WHERE method = 'yake'
    """)
    row = cur.fetchone()
    
    print(f"   YAKE åˆ†æ•°åˆ†å¸ƒ:")
    print(f"      MIN: {row['min_s']:.4f}")
    print(f"      MAX: {row['max_s']:.4f}")
    print(f"      AVG: {row['avg_s']:.4f}")
    
    # æ£€æŸ¥æç«¯å€¼
    cur = conn.execute("""
        SELECT COUNT(*) FROM paper_keywords 
        WHERE method = 'yake' AND (score < 0.01 OR score > 0.99)
    """)
    extreme_count = cur.fetchone()[0]
    extreme_rate = extreme_count / len(all_keywords) * 100 if all_keywords else 0
    print(f"   æç«¯å€¼ (<0.01 æˆ– >0.99): {extreme_count} ({extreme_rate:.1f}%)")
    
    # ========================================
    # éªŒæ”¶ Eï¼šå¹‚ç­‰æ€§
    # ========================================
    print("\n" + "-" * 70)
    print("E. å¹‚ç­‰æ€§ï¼ˆIdempotencyï¼‰")
    print("-" * 70)
    
    cur = conn.execute("""
        SELECT paper_id, keyword, method, COUNT(*) as cnt
        FROM paper_keywords
        GROUP BY paper_id, keyword, method
        HAVING cnt > 1
    """)
    duplicates = cur.fetchall()
    
    print(f"   é‡å¤è®°å½•æ•°: {len(duplicates)} {'âœ…' if len(duplicates) == 0 else 'âŒ'}")
    
    # ========================================
    # éªŒæ”¶ Fï¼šåŒä¹‰å½’å¹¶æ•ˆæœ
    # ========================================
    print("\n" + "-" * 70)
    print("F. åŒä¹‰å½’å¹¶æ•ˆæœ")
    print("-" * 70)
    
    # æ£€æŸ¥å¸¸è§å½’å¹¶è¯
    synonym_targets = ["large language model", "diffusion model", "transformer", "vision transformer"]
    for target in synonym_targets:
        cur = conn.execute("""
            SELECT COUNT(*) FROM paper_keywords 
            WHERE method = 'yake' AND keyword = ?
        """, (target,))
        cnt = cur.fetchone()[0]
        if cnt > 0:
            print(f"   '{target}': {cnt} æ¬¡")
    
    # ========================================
    # æ€»ç»“
    # ========================================
    print("\n" + "=" * 70)
    print("ğŸ“‹ éªŒæ”¶æ€»ç»“")
    print("=" * 70)
    
    issues = []
    if coverage < 95:
        issues.append(f"è¦†ç›–ç‡ä¸è¶³ ({coverage:.1f}%)")
    if noise_rate >= 10:
        issues.append(f"å™ªå£°ç‡è¿‡é«˜ ({noise_rate:.1f}%)")
    if len(duplicates) > 0:
        issues.append(f"å­˜åœ¨é‡å¤è®°å½• ({len(duplicates)})")
    
    if not issues:
        print("âœ… å…¨éƒ¨é€šè¿‡ï¼")
    else:
        print("âŒ å­˜åœ¨é—®é¢˜:")
        for issue in issues:
            print(f"   - {issue}")
    
    conn.close()


if __name__ == "__main__":
    main()
