"""
ä¼šè®®é…ç½®ä¸è®ºæ–‡çˆ¬å–
"""

from typing import List, Optional, Dict
from tqdm import tqdm

from .client import OpenReviewClient, create_client
from .models import Paper
from config import VENUES, VenueConfig


def parse_note_to_paper(note, venue: str, year: int) -> Optional[Paper]:
    """
    å°† OpenReview Note è½¬æ¢ä¸º Paper å¯¹è±¡
    
    Args:
        note: OpenReview Note å¯¹è±¡
        venue: ä¼šè®®åç§°
        year: å¹´ä»½
        
    Returns:
        Paper å¯¹è±¡ï¼Œå¦‚æœè§£æå¤±è´¥è¿”å› None
    """
    try:
        content = note.content
        
        # è·å–æ ‡é¢˜
        title = content.get("title", {})
        if isinstance(title, dict):
            title = title.get("value", "")
        
        # è·å–æ‘˜è¦
        abstract = content.get("abstract", {})
        if isinstance(abstract, dict):
            abstract = abstract.get("value", "")
        
        # è·å–ä½œè€…
        authors = content.get("authors", {})
        if isinstance(authors, dict):
            authors = authors.get("value", [])
        if isinstance(authors, str):
            authors = [authors]
        
        # è·å–å…³é”®è¯
        keywords = content.get("keywords", {})
        if isinstance(keywords, dict):
            keywords = keywords.get("value", [])
        if isinstance(keywords, str):
            keywords = [keywords]
        
        # æ„å»º URL
        url = f"https://openreview.net/forum?id={note.id}"
        
        # PDF URL
        pdf_url = content.get("pdf", {})
        if isinstance(pdf_url, dict):
            pdf_url = pdf_url.get("value")
        if pdf_url and not pdf_url.startswith("http"):
            pdf_url = f"https://openreview.net{pdf_url}"
        
        return Paper(
            id=note.id,
            title=title,
            abstract=abstract,
            authors=authors if isinstance(authors, list) else [],
            venue=venue,
            year=year,
            url=url,
            keywords=keywords if isinstance(keywords, list) else [],
            pdf_url=pdf_url,
        )
    except Exception as e:
        print(f"è§£æè®ºæ–‡å¤±è´¥: {e}")
        return None


def scrape_venue(
    venue_config: VenueConfig,
    year: int,
    client: Optional[OpenReviewClient] = None,
    limit: Optional[int] = None,
    show_progress: bool = True,
) -> List[Paper]:
    """
    çˆ¬å–æŒ‡å®šä¼šè®®æŒ‡å®šå¹´ä»½çš„è®ºæ–‡
    
    Args:
        venue_config: ä¼šè®®é…ç½®
        year: å¹´ä»½
        client: OpenReview å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œé»˜è®¤åˆ›å»ºæ–°çš„ï¼‰
        limit: é™åˆ¶è¿”å›è®ºæ–‡æ•°é‡
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
    Returns:
        è®ºæ–‡åˆ—è¡¨
    """
    if client is None:
        client = create_client()
    
    venue_id = venue_config.venue_id_pattern.format(year=year)
    papers = []
    
    print(f"\nğŸ” æ­£åœ¨çˆ¬å– {venue_config.name} {year}...")
    
    notes = list(client.get_accepted_papers(venue_id, limit=limit))
    
    if show_progress:
        notes = tqdm(notes, desc=f"{venue_config.name} {year}")
    
    for note in notes:
        paper = parse_note_to_paper(note, venue_config.name, year)
        if paper:
            papers.append(paper)
    
    print(f"âœ… {venue_config.name} {year}: è·å– {len(papers)} ç¯‡è®ºæ–‡")
    return papers


def scrape_all_venues(
    venues: Optional[Dict[str, VenueConfig]] = None,
    years: Optional[List[int]] = None,
    limit_per_venue: Optional[int] = None,
    show_progress: bool = True,
    max_age_days: int = 7,
    repository = None,
) -> List[Paper]:
    """
    çˆ¬å–æ‰€æœ‰é…ç½®çš„ä¼šè®®è®ºæ–‡
    
    Args:
        venues: ä¼šè®®é…ç½®å­—å…¸ï¼ˆé»˜è®¤ä½¿ç”¨ config ä¸­çš„é…ç½®ï¼‰
        years: è¦çˆ¬å–çš„å¹´ä»½åˆ—è¡¨ï¼ˆé»˜è®¤ä½¿ç”¨å„ä¼šè®®é…ç½®çš„å¹´ä»½ï¼‰
        limit_per_venue: æ¯ä¸ªä¼šè®®å¹´ä»½çš„è®ºæ–‡æ•°é‡é™åˆ¶
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        max_age_days: æœ€å¤§çˆ¬å–é—´éš”å¤©æ•°ï¼Œåœ¨æ­¤æ—¶é—´å†…çˆ¬å–è¿‡çš„ä¼šè®®å°†è¢«è·³è¿‡ï¼ˆé»˜è®¤ 7 å¤©ï¼‰
        repository: æ•°æ®åº“ä»“åº“ï¼ˆç”¨äºæ£€æŸ¥å’Œè®°å½•çˆ¬å–æ—¥å¿—ï¼‰
        
    Returns:
        æ‰€æœ‰è®ºæ–‡åˆ—è¡¨
    """
    if venues is None:
        venues = VENUES
    
    client = create_client()
    all_papers = []
    skipped_count = 0
    
    for venue_name, venue_config in venues.items():
        venue_years = years if years is not None else venue_config.years
        
        for year in venue_years:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦çˆ¬å–
            if repository is not None and not repository.should_scrape(venue_config.name, year, max_age_days):
                print(f"â­ï¸ è·³è¿‡ {venue_config.name} {year}ï¼ˆ{max_age_days} å¤©å†…å·²çˆ¬å–ï¼‰")
                skipped_count += 1
                continue
            
            try:
                papers = scrape_venue(
                    venue_config,
                    year,
                    client=client,
                    limit=limit_per_venue,
                    show_progress=show_progress,
                )
                all_papers.extend(papers)
                
                # è®°å½•çˆ¬å–æ—¥å¿—
                if repository is not None and papers:
                    repository.log_scrape(venue_config.name, year, len(papers))
                    
            except Exception as e:
                print(f"âŒ çˆ¬å– {venue_name} {year} å¤±è´¥: {e}")
                continue
    
    print(f"\nğŸ“Š æ€»è®¡çˆ¬å– {len(all_papers)} ç¯‡è®ºæ–‡ï¼ˆè·³è¿‡ {skipped_count} ä¸ªä¼šè®®å¹´ä»½ï¼‰")
    return all_papers

