"""
OpenAlex API å®¢æˆ·ç«¯

ä½œä¸º Structured Layer çš„é”šç‚¹æ•°æ®æºï¼š
- æä¾›è®ºæ–‡ä¸ä¼šè®®ï¼ˆvenueï¼‰çš„ç»“æ„åŒ–å…³ç³»
- ç”¨äºä¼šè®®è¯†åˆ«ä¸æ ¡éªŒ
- è¡¥å…… DOIã€venue_id ç­‰å­—æ®µ

OpenAlex æ˜¯å…è´¹ã€å¼€æ”¾çš„å­¦æœ¯æ•°æ®åº“ï¼Œæ”¯æŒå¤§è§„æ¨¡æ‰¹é‡è®¿é—®ã€‚
https://docs.openalex.org/
"""

import time
import requests
from typing import List, Optional, Dict, Any, Iterator
from datetime import datetime
from dataclasses import dataclass

from .models import RawPaper, Venue


# OpenAlex API é…ç½®
OPENALEX_API_URL = "https://api.openalex.org"

# é»˜è®¤å­—æ®µ
WORK_FIELDS = [
    "id", "doi", "title", "display_name", "publication_year",
    "abstract_inverted_index", "authorships", "primary_location",
    "type", "language", "open_access", "cited_by_count",
    "concepts", "topics"
]


@dataclass  
class OpenAlexVenue:
    """OpenAlex æ¥æºï¼ˆæœŸåˆŠ/ä¼šè®®ï¼‰"""
    openalex_id: str
    display_name: str
    issn: List[str] = None
    type: str = None  # journal, repository, conference


class OpenAlexClient:
    """OpenAlex API å®¢æˆ·ç«¯"""
    
    def __init__(self, email: str = None, delay: float = 0.1):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            email: ç”¨äº polite poolï¼ˆå¯è·å¾—æ›´é«˜é€Ÿç‡é™åˆ¶ï¼‰
            delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
        """
        self.email = email
        self.delay = delay
        self.session = requests.Session()
        
        # è®¾ç½® User-Agentï¼ˆOpenAlex æ¨èï¼‰
        headers = {"User-Agent": "DeepTrender/1.0"}
        if email:
            headers["User-Agent"] = f"DeepTrender/1.0 (mailto:{email})"
        self.session.headers.update(headers)
        
        self._last_request = 0
    
    def _wait_for_rate_limit(self):
        """éµå®ˆé€Ÿç‡é™åˆ¶"""
        elapsed = time.time() - self._last_request
        if elapsed < self.delay:
            time.sleep(self.delay - elapsed)
        self._last_request = time.time()
    
    def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
        """å‘é€ API è¯·æ±‚"""
        self._wait_for_rate_limit()
        
        url = f"{OPENALEX_API_URL}/{endpoint}"
        params = params or {}
        
        # æ·»åŠ  email ç”¨äº polite pool
        if self.email:
            params["mailto"] = self.email
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"OpenAlex API è¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def search_works(
        self,
        venue: str = None,
        year: int = None,
        concept: str = None,
        topic: str = None,
        per_page: int = 100,
        max_results: int = 1000,
    ) -> List[RawPaper]:
        """
        æœç´¢è®ºæ–‡
        
        Args:
            venue: ä¼šè®®/æœŸåˆŠåç§°ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
            year: å‘è¡¨å¹´ä»½
            concept: æ¦‚å¿µ IDï¼ˆå¦‚ computer visionï¼‰
            topic: ä¸»é¢˜ ID
            per_page: æ¯é¡µæ•°é‡
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            RawPaper åˆ—è¡¨
        """
        filters = []
        
        if venue:
            filters.append(f"primary_location.source.display_name.search:{venue}")
        if year:
            filters.append(f"publication_year:{year}")
        if concept:
            filters.append(f"concepts.id:{concept}")
        if topic:
            filters.append(f"topics.id:{topic}")
        
        filter_str = ",".join(filters) if filters else None
        
        all_papers = []
        cursor = "*"
        
        while len(all_papers) < max_results:
            params = {
                "per_page": min(per_page, max_results - len(all_papers)),
                "cursor": cursor,
            }
            if filter_str:
                params["filter"] = filter_str
            
            data = self._make_request("works", params)
            if not data or "results" not in data:
                break
            
            results = data["results"]
            if not results:
                break
            
            for work in results:
                paper = self._parse_work(work)
                if paper:
                    all_papers.append(paper)
            
            # è·å–ä¸‹ä¸€é¡µæ¸¸æ ‡
            cursor = data.get("meta", {}).get("next_cursor")
            if not cursor:
                break
            
            print(f"   å·²è·å– {len(all_papers)} ç¯‡è®ºæ–‡...")
        
        return all_papers
    
    def search_by_venue_year(
        self,
        venue_name: str,
        year: int,
        max_results: int = 2000,
    ) -> List[RawPaper]:
        """
        æŒ‰ä¼šè®®å’Œå¹´ä»½æœç´¢è®ºæ–‡
        
        Args:
            venue_name: ä¼šè®®åç§°ï¼ˆå¦‚ "CVPR", "NeurIPS"ï¼‰
            year: å¹´ä»½
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            RawPaper åˆ—è¡¨
        """
        print(f"ğŸ” æ­£åœ¨ä» OpenAlex è·å– {venue_name} {year}...")
        
        papers = self.search_works(
            venue=venue_name,
            year=year,
            max_results=max_results,
        )
        
        print(f"âœ… OpenAlex {venue_name} {year}: è·å– {len(papers)} ç¯‡è®ºæ–‡")
        return papers
    
    def get_work(self, work_id: str) -> Optional[RawPaper]:
        """
        è·å–å•ç¯‡è®ºæ–‡
        
        Args:
            work_id: OpenAlex Work IDï¼ˆå¦‚ "W2741809807"ï¼‰æˆ– DOI
            
        Returns:
            RawPaper
        """
        # å¤„ç†ä¸åŒ ID æ ¼å¼
        if work_id.startswith("10."):
            endpoint = f"works/doi:{work_id}"
        elif work_id.startswith("W"):
            endpoint = f"works/{work_id}"
        else:
            endpoint = f"works/{work_id}"
        
        data = self._make_request(endpoint)
        if data:
            return self._parse_work(data)
        return None
    
    def get_venue(self, venue_id: str) -> Optional[OpenAlexVenue]:
        """
        è·å–ä¼šè®®/æœŸåˆŠä¿¡æ¯
        
        Args:
            venue_id: OpenAlex Source ID
            
        Returns:
            OpenAlexVenue
        """
        data = self._make_request(f"sources/{venue_id}")
        if data:
            return OpenAlexVenue(
                openalex_id=data.get("id", ""),
                display_name=data.get("display_name", ""),
                issn=data.get("issn", []),
                type=data.get("type"),
            )
        return None
    
    def search_venues(self, query: str, limit: int = 10) -> List[OpenAlexVenue]:
        """
        æœç´¢ä¼šè®®/æœŸåˆŠ
        
        Args:
            query: æœç´¢è¯
            limit: è¿”å›æ•°é‡
            
        Returns:
            OpenAlexVenue åˆ—è¡¨
        """
        params = {
            "search": query,
            "per_page": limit,
        }
        
        data = self._make_request("sources", params)
        if not data or "results" not in data:
            return []
        
        return [
            OpenAlexVenue(
                openalex_id=source.get("id", ""),
                display_name=source.get("display_name", ""),
                issn=source.get("issn", []),
                type=source.get("type"),
            )
            for source in data["results"]
        ]
    
    def _parse_work(self, work: Dict[str, Any]) -> Optional[RawPaper]:
        """è§£æ OpenAlex Work ä¸º RawPaper"""
        try:
            # OpenAlex ID
            openalex_id = work.get("id", "").split("/")[-1]
            if not openalex_id:
                return None
            
            # æ ‡é¢˜
            title = work.get("display_name") or work.get("title", "")
            
            # æ‘˜è¦ï¼ˆéœ€è¦ä» inverted index é‡å»ºï¼‰
            abstract = self._rebuild_abstract(work.get("abstract_inverted_index"))
            
            # ä½œè€…
            authors = []
            for authorship in work.get("authorships", []):
                author = authorship.get("author", {})
                name = author.get("display_name", "")
                if name:
                    authors.append(name)
            
            # å¹´ä»½
            year = work.get("publication_year")
            
            # æ¥æº/ä¼šè®®
            venue_raw = None
            primary_location = work.get("primary_location") or {}
            source = primary_location.get("source") or {}
            if source:
                venue_raw = source.get("display_name")
            
            # DOI
            doi = work.get("doi", "")
            if doi and doi.startswith("https://doi.org/"):
                doi = doi.replace("https://doi.org/", "")
            
            # ç±»å‹
            work_type = work.get("type", "")
            
            return RawPaper(
                source="openalex",
                source_paper_id=openalex_id,
                title=title,
                abstract=abstract,
                authors=authors,
                year=year,
                venue_raw=venue_raw,
                journal_ref=None,
                comments=None,
                categories=work_type,
                doi=doi,
                raw_json={
                    "id": work.get("id"),
                    "type": work_type,
                    "open_access": work.get("open_access"),
                    "cited_by_count": work.get("cited_by_count"),
                    "concepts": [c.get("display_name") for c in work.get("concepts", [])[:5]],
                    "primary_location": primary_location,
                },
                retrieved_at=datetime.now(),
            )
            
        except Exception as e:
            print(f"è§£æ OpenAlex work å¤±è´¥: {e}")
            return None
    
    def _rebuild_abstract(self, inverted_index: Dict[str, List[int]]) -> str:
        """ä» inverted index é‡å»ºæ‘˜è¦"""
        if not inverted_index:
            return ""
        
        try:
            # æ‰¾å‡ºæœ€å¤§ä½ç½®
            max_pos = 0
            for positions in inverted_index.values():
                if positions:
                    max_pos = max(max_pos, max(positions))
            
            # é‡å»º
            words = [""] * (max_pos + 1)
            for word, positions in inverted_index.items():
                for pos in positions:
                    words[pos] = word
            
            return " ".join(words)
        except:
            return ""


def create_openalex_client(email: str = None) -> OpenAlexClient:
    """åˆ›å»º OpenAlex å®¢æˆ·ç«¯"""
    return OpenAlexClient(email=email)
