"""
Structuring Agent

è´Ÿè´£å°† Raw Layer çš„æ•°æ®å¤„ç†ä¸º Structured Layerã€‚

èŒè´£ï¼š
- æ ‡é¢˜æ ‡å‡†åŒ–
- ä¼šè®®è¯†åˆ«ï¼ˆä» commentsã€venue_raw ç­‰å­—æ®µï¼‰
- é¢†åŸŸåˆ†ç±»
- è·¨æºå»é‡
- åˆ›å»º paper_sources å…³è”
"""

import sys
import re
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from datetime import datetime

# ç¡®ä¿ src ç›®å½•åœ¨è·¯å¾„ä¸­
_src_dir = Path(__file__).parent.parent
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))

from database import (
    get_raw_repository, get_structured_repository,
    RawRepository, StructuredRepository
)
from scraper.models import RawPaper, Paper, Venue, PaperSource


# ä¼šè®®è¯†åˆ«æ¨¡å¼
VENUE_PATTERNS = {
    # ML é¡¶ä¼š
    "ICML": [r"\bICML\b", r"International Conference on Machine Learning"],
    "NeurIPS": [r"\bNeurIPS\b", r"\bNIPS\b", r"Neural Information Processing"],
    "ICLR": [r"\bICLR\b", r"International Conference on Learning Representations"],
    
    # CV é¡¶ä¼š
    "CVPR": [r"\bCVPR\b", r"Computer Vision and Pattern Recognition"],
    "ICCV": [r"\bICCV\b", r"International Conference on Computer Vision"],
    "ECCV": [r"\bECCV\b", r"European Conference on Computer Vision"],
    
    # NLP é¡¶ä¼š
    "ACL": [r"\bACL\s*20\d{2}\b", r"Annual Meeting of the Association for Computational Linguistics"],
    "EMNLP": [r"\bEMNLP\b", r"Empirical Methods in Natural Language Processing"],
    "NAACL": [r"\bNAACL\b", r"North American.*ACL"],
    
    # AI ç»¼åˆ
    "AAAI": [r"\bAAAI\b", r"AAAI Conference on Artificial Intelligence"],
    "IJCAI": [r"\bIJCAI\b", r"International Joint Conference on Artificial Intelligence"],
    
    # å…¶ä»–
    "CoRL": [r"\bCoRL\b", r"Conference on Robot Learning"],
    "AISTATS": [r"\bAISTATS\b", r"Artificial Intelligence and Statistics"],
}

# é¢†åŸŸåˆ†ç±»
DOMAIN_CATEGORIES = {
    "CV": ["cs.CV", "computer vision", "image", "video", "visual"],
    "NLP": ["cs.CL", "natural language", "nlp", "text", "language model"],
    "ML": ["cs.LG", "stat.ML", "machine learning", "deep learning"],
    "RL": ["cs.AI", "reinforcement learning", "robot", "control"],
    "AI": ["artificial intelligence", "neural network"],
}


class StructuringAgent:
    """
    æ•°æ®ç»“æ„åŒ– Agent
    
    è´Ÿè´£å°† Raw Layer è½¬æ¢ä¸º Structured Layerã€‚
    """
    
    def __init__(
        self,
        raw_repo: RawRepository = None,
        structured_repo: StructuredRepository = None,
    ):
        self.raw_repo = raw_repo or get_raw_repository()
        self.structured_repo = structured_repo or get_structured_repository()
        self._venue_cache: Dict[str, int] = {}  # canonical_name -> venue_id
    
    def process_raw_paper(self, raw_paper: RawPaper) -> Optional[Paper]:
        """
        å¤„ç†å•ç¯‡åŸå§‹è®ºæ–‡
        
        Args:
            raw_paper: åŸå§‹è®ºæ–‡
            
        Returns:
            ç»“æ„åŒ–è®ºæ–‡ï¼ˆå¦‚æœå¤„ç†æˆåŠŸï¼‰
        """
        # 1. æ ‡é¢˜æ ‡å‡†åŒ–
        canonical_title = self._normalize_title(raw_paper.title)
        if not canonical_title:
            return None
        
        # 2. ä¼šè®®è¯†åˆ«
        venue_name, confidence = self._detect_venue(raw_paper)
        
        # 3. é¢†åŸŸåˆ†ç±»
        domain = self._classify_domain(raw_paper)
        
        # 4. ç¡®å®š venue_type
        venue_type = self._determine_venue_type(raw_paper, venue_name)
        
        # 5. ç¡®å®š quality_flag
        quality_flag = self._determine_quality(raw_paper, venue_name)
        
        # 6. è·å–æˆ–åˆ›å»º venue
        venue_id = None
        if venue_name:
            venue_id = self._get_or_create_venue(venue_name, domain)
        
        return Paper(
            canonical_title=canonical_title,
            abstract=raw_paper.abstract or "",
            authors=raw_paper.authors,
            year=raw_paper.year,
            venue_id=venue_id,
            venue_type=venue_type,
            domain=domain,
            quality_flag=quality_flag,
            doi=raw_paper.doi,
            venue_name=venue_name,
        )
    
    def _normalize_title(self, title: str) -> str:
        """æ ‡å‡†åŒ–æ ‡é¢˜"""
        if not title:
            return ""
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        title = " ".join(title.split())
        
        # ç§»é™¤é¦–å°¾ç©ºæ ¼
        title = title.strip()
        
        return title
    
    def _detect_venue(self, raw_paper: RawPaper) -> Tuple[Optional[str], float]:
        """
        æ£€æµ‹ä¼šè®®
        
        Returns:
            (venue_name, confidence)
        """
        # æ¥æºä¼˜å…ˆçº§ï¼šOpenReview > venue_raw > comments > journal_ref
        
        # 1. OpenReview æ¥æºç›´æ¥ä¿¡ä»»
        if raw_paper.source == "openreview" and raw_paper.venue_raw:
            return (raw_paper.venue_raw, 1.0)
        
        # 2. æ£€æŸ¥ venue_raw
        if raw_paper.venue_raw:
            venue = self._match_venue_patterns(raw_paper.venue_raw)
            if venue:
                return (venue, 0.9)
        
        # 3. æ£€æŸ¥ commentsï¼ˆarXiv å¸¸ç”¨ï¼‰
        if raw_paper.comments:
            venue = self._match_venue_patterns(raw_paper.comments)
            if venue:
                return (venue, 0.7)
        
        # 4. æ£€æŸ¥ journal_ref
        if raw_paper.journal_ref:
            venue = self._match_venue_patterns(raw_paper.journal_ref)
            if venue:
                return (venue, 0.8)
        
        return (None, 0.0)
    
    def _match_venue_patterns(self, text: str) -> Optional[str]:
        """åŒ¹é…ä¼šè®®æ¨¡å¼"""
        text_lower = text.lower()
        
        for venue_name, patterns in VENUE_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    return venue_name
        
        return None
    
    def _classify_domain(self, raw_paper: RawPaper) -> Optional[str]:
        """åˆ†ç±»é¢†åŸŸ"""
        # æ£€æŸ¥ arXiv categories
        if raw_paper.categories:
            categories = raw_paper.categories.lower()
            for domain, keywords in DOMAIN_CATEGORIES.items():
                for kw in keywords:
                    if kw in categories:
                        return domain
        
        # æ£€æŸ¥æ ‡é¢˜å’Œæ‘˜è¦
        text = f"{raw_paper.title} {raw_paper.abstract}".lower()
        
        domain_scores = {}
        for domain, keywords in DOMAIN_CATEGORIES.items():
            score = sum(1 for kw in keywords if kw in text)
            if score > 0:
                domain_scores[domain] = score
        
        if domain_scores:
            return max(domain_scores, key=domain_scores.get)
        
        return None
    
    def _determine_venue_type(self, raw_paper: RawPaper, venue_name: str) -> str:
        """ç¡®å®š venue ç±»å‹"""
        if venue_name:
            return "conference"
        
        if raw_paper.source == "arxiv":
            if raw_paper.journal_ref:
                return "journal"
            return "preprint"
        
        if raw_paper.categories and "article" in raw_paper.categories.lower():
            return "journal"
        
        return "unknown"
    
    def _determine_quality(self, raw_paper: RawPaper, venue_name: str) -> str:
        """ç¡®å®šè´¨é‡æ ‡å¿—"""
        # OpenReview é»˜è®¤ä¸º accepted
        if raw_paper.source == "openreview":
            return "accepted"
        
        # æœ‰æ˜ç¡®ä¼šè®®çš„è§†ä¸º accepted
        if venue_name:
            # æ£€æŸ¥æ˜¯å¦æœ‰ "accepted" å…³é”®è¯
            comments = raw_paper.comments or ""
            if "accepted" in comments.lower():
                return "accepted"
            # æœ‰ä¼šè®®åä½†ä¸ç¡®å®šæ˜¯å¦æ¥å—
            return "unknown"
        
        return "unknown"
    
    def _get_or_create_venue(self, venue_name: str, domain: str) -> int:
        """è·å–æˆ–åˆ›å»º venue"""
        # æ£€æŸ¥ç¼“å­˜
        if venue_name in self._venue_cache:
            return self._venue_cache[venue_name]
        
        # æ£€æŸ¥æ•°æ®åº“
        venue = self.structured_repo.get_venue_by_name(venue_name)
        if venue:
            self._venue_cache[venue_name] = venue.venue_id
            return venue.venue_id
        
        # åˆ›å»ºæ–° venue
        new_venue = Venue(
            canonical_name=venue_name,
            domain=domain,
            venue_type="conference",
        )
        venue_id = self.structured_repo.save_venue(new_venue)
        self._venue_cache[venue_name] = venue_id
        return venue_id
    
    def _find_existing_paper(self, title: str, year: int) -> Optional[int]:
        """
        æŸ¥æ‰¾å·²å­˜åœ¨çš„è®ºæ–‡ï¼ˆåŸºäºæ ‡é¢˜å»é‡ï¼‰
        
        Args:
            title: æ ‡å‡†åŒ–æ ‡é¢˜
            year: å¹´ä»½
            
        Returns:
            paper_id å¦‚æœå­˜åœ¨ï¼Œå¦åˆ™ None
        """
        # æ ‡å‡†åŒ–æ ‡é¢˜ç”¨äºåŒ¹é…
        normalized = self._normalize_title(title).lower()
        
        # æŸ¥è¯¢æ•°æ®åº“
        paper_id = self.structured_repo.find_paper_by_title(normalized, year)
        return paper_id
    
    def process_batch(
        self,
        source: str = None,
        limit: int = 1000,
    ) -> Dict[str, int]:
        """
        æ‰¹é‡å¤„ç†æœªå¤„ç†çš„åŸå§‹è®ºæ–‡
        
        Args:
            source: é™å®šæ•°æ®æº
            limit: æ‰¹é‡å¤§å°
            
        Returns:
            å¤„ç†ç»Ÿè®¡
        """
        print(f"\nğŸ“ [Structuring] æ­£åœ¨å¤„ç†æœªç»“æ„åŒ–çš„è®ºæ–‡...")
        
        raw_papers = self.raw_repo.get_unprocessed_raw_papers(source=source, limit=limit)
        
        if not raw_papers:
            print("   æ²¡æœ‰éœ€è¦å¤„ç†çš„è®ºæ–‡")
            return {"processed": 0, "success": 0, "failed": 0, "merged": 0}
        
        print(f"   æ‰¾åˆ° {len(raw_papers)} ç¯‡å¾…å¤„ç†è®ºæ–‡")
        
        success = 0
        failed = 0
        merged = 0  # å¤šæºåˆå¹¶è®¡æ•°
        
        for raw_paper in raw_papers:
            try:
                paper = self.process_raw_paper(raw_paper)
                if paper:
                    # å°è¯•æŸ¥æ‰¾å·²å­˜åœ¨çš„è®ºæ–‡ï¼ˆåŸºäºæ ‡é¢˜å»é‡ï¼‰
                    existing_paper_id = self._find_existing_paper(paper.canonical_title, paper.year)
                    
                    if existing_paper_id:
                        # å·²å­˜åœ¨ï¼Œåªæ·»åŠ  source å…³è”
                        self.structured_repo.link_paper_source(
                            paper_id=existing_paper_id,
                            raw_id=raw_paper.raw_id,
                            source=raw_paper.source,
                        )
                        merged += 1
                    else:
                        # æ–°è®ºæ–‡ï¼Œä¿å­˜å¹¶å…³è”
                        paper_id = self.structured_repo.save_paper(paper)
                        self.structured_repo.link_paper_source(
                            paper_id=paper_id,
                            raw_id=raw_paper.raw_id,
                            source=raw_paper.source,
                        )
                    
                    success += 1
                else:
                    failed += 1
            except Exception as e:
                print(f"   å¤„ç†å¤±è´¥: {e}")
                failed += 1
        
        print(f"âœ… [Structuring] å¤„ç†å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {failed}, åˆå¹¶ {merged}")
        
        return {
            "processed": len(raw_papers),
            "success": success,
            "failed": failed,
            "merged": merged,
        }
    
    def run(self, limit: int = None) -> Dict[str, int]:
        """
        è¿è¡Œç»“æ„åŒ–æµç¨‹
        
        Args:
            limit: å¤„ç†æ•°é‡é™åˆ¶
            
        Returns:
            å¤„ç†ç»Ÿè®¡
        """
        print("\n" + "=" * 60)
        print("ğŸ“ [Structuring Agent] å¼€å§‹ç»“æ„åŒ–å¤„ç†")
        print("=" * 60)
        
        total_stats = {"processed": 0, "success": 0, "failed": 0}
        
        # æŒ‰æ•°æ®æºåˆ†æ‰¹å¤„ç†
        for source in ["openreview", "arxiv", "openalex", "s2"]:
            batch_limit = limit or 1000
            stats = self.process_batch(source=source, limit=batch_limit)
            
            total_stats["processed"] += stats["processed"]
            total_stats["success"] += stats["success"]
            total_stats["failed"] += stats["failed"]
            
            if limit and total_stats["processed"] >= limit:
                break
        
        paper_count = self.structured_repo.get_paper_count()
        print(f"\nğŸ“Š [Structuring] Structured Layer ç°æœ‰ {paper_count} ç¯‡è®ºæ–‡")
        
        return total_stats


def run_structuring(limit: int = None) -> Dict[str, int]:
    """è¿è¡Œç»“æ„åŒ–çš„ä¾¿æ·å‡½æ•°"""
    agent = StructuringAgent()
    return agent.run(limit=limit)
