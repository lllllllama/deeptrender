"""
Ingestion Agent

è´Ÿè´£ä»å„æ•°æ®æºé‡‡é›†åŸå§‹è®ºæ–‡æ•°æ®åˆ° Raw Layerã€‚

èŒè´£ï¼š
- ä» arXivã€OpenAlexã€Semantic Scholarã€OpenReview é‡‡é›†æ•°æ®
- ä¿å­˜å®Œæ•´åŸå§‹æ•°æ®åˆ° raw_papers è¡¨
- ä¸åšä»»ä½•æ•°æ®è§£é‡Šæˆ–æ ‡å‡†åŒ–
"""

import sys
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime

# ç¡®ä¿ src ç›®å½•åœ¨è·¯å¾„ä¸­
_src_dir = Path(__file__).parent.parent
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))

from database import get_raw_repository, RawRepository
from scraper.models import RawPaper
from scraper.arxiv_client import ArxivClient, create_arxiv_client, DEFAULT_CATEGORIES
from scraper.openalex_client import OpenAlexClient, create_openalex_client
from scraper.semantic_scholar import SemanticScholarClient, S2_VENUES
from scraper.client import OpenReviewClient, create_client as create_or_client
from scraper.venues import parse_note_to_paper
from config import VENUES


class IngestionAgent:
    """
    åŸå§‹æ•°æ®é‡‡é›† Agent
    
    è´Ÿè´£å°†å„æ•°æ®æºçš„è®ºæ–‡é‡‡é›†åˆ° Raw Layerã€‚
    """
    
    def __init__(
        self,
        repository: RawRepository = None,
        arxiv_client: ArxivClient = None,
        openalex_client: OpenAlexClient = None,
        s2_client: SemanticScholarClient = None,
        or_client: OpenReviewClient = None,
    ):
        self.repo = repository or get_raw_repository()
        self.arxiv = arxiv_client
        self.openalex = openalex_client
        self.s2 = s2_client
        self.or_client = or_client
    
    def _get_arxiv_client(self) -> ArxivClient:
        """æ‡’åŠ è½½ arXiv å®¢æˆ·ç«¯"""
        if self.arxiv is None:
            self.arxiv = create_arxiv_client()
        return self.arxiv
    
    def _get_openalex_client(self) -> OpenAlexClient:
        """æ‡’åŠ è½½ OpenAlex å®¢æˆ·ç«¯"""
        if self.openalex is None:
            self.openalex = create_openalex_client()
        return self.openalex
    
    def _get_s2_client(self) -> SemanticScholarClient:
        """æ‡’åŠ è½½ Semantic Scholar å®¢æˆ·ç«¯"""
        if self.s2 is None:
            self.s2 = SemanticScholarClient()
        return self.s2
    
    def _get_or_client(self) -> OpenReviewClient:
        """æ‡’åŠ è½½ OpenReview å®¢æˆ·ç«¯"""
        if self.or_client is None:
            self.or_client = create_or_client()
        return self.or_client
    
    # ========== arXiv é‡‡é›† ==========
    
    def ingest_arxiv_recent(
        self,
        categories: List[str] = None,
        days: int = 7,
        max_results: int = 1000,
    ) -> int:
        """
        é‡‡é›† arXiv æœ€è¿‘çš„è®ºæ–‡
        
        Args:
            categories: arXiv ç±»åˆ«åˆ—è¡¨
            days: å¤©æ•°
            max_results: æœ€å¤§æ•°é‡
            
        Returns:
            é‡‡é›†çš„è®ºæ–‡æ•°é‡
        """
        client = self._get_arxiv_client()
        categories = categories or DEFAULT_CATEGORIES
        
        print(f"\nğŸ“¥ [Ingestion] æ­£åœ¨ä» arXiv é‡‡é›†æœ€è¿‘ {days} å¤©çš„è®ºæ–‡...")
        
        papers = client.search_recent(
            categories=categories,
            days=days,
            max_results=max_results,
        )
        
        saved_count = 0
        for paper in papers:
            try:
                self.repo.save_raw_paper(paper)
                saved_count += 1
            except Exception as e:
                print(f"   ä¿å­˜å¤±è´¥: {e}")
        
        print(f"âœ… arXiv: å·²ä¿å­˜ {saved_count}/{len(papers)} ç¯‡åˆ° Raw Layer")
        return saved_count
    
    def ingest_arxiv_category(
        self,
        category: str,
        max_results: int = 1000,
    ) -> int:
        """æŒ‰ç±»åˆ«é‡‡é›† arXiv è®ºæ–‡"""
        client = self._get_arxiv_client()
        
        print(f"\nğŸ“¥ [Ingestion] æ­£åœ¨ä» arXiv é‡‡é›† {category} ç±»åˆ«...")
        
        papers = client.search_by_category(category, max_results)
        
        saved_count = 0
        for paper in papers:
            try:
                self.repo.save_raw_paper(paper)
                saved_count += 1
            except Exception as e:
                pass
        
        print(f"âœ… arXiv {category}: å·²ä¿å­˜ {saved_count} ç¯‡")
        return saved_count
    
    # ========== OpenAlex é‡‡é›† ==========
    
    def ingest_openalex_venue(
        self,
        venue_name: str,
        year: int,
        max_results: int = 2000,
    ) -> int:
        """
        æŒ‰ä¼šè®®é‡‡é›† OpenAlex è®ºæ–‡
        
        Args:
            venue_name: ä¼šè®®åç§°
            year: å¹´ä»½
            max_results: æœ€å¤§æ•°é‡
            
        Returns:
            é‡‡é›†æ•°é‡
        """
        client = self._get_openalex_client()
        
        print(f"\nğŸ“¥ [Ingestion] æ­£åœ¨ä» OpenAlex é‡‡é›† {venue_name} {year}...")
        
        papers = client.search_by_venue_year(venue_name, year, max_results)
        
        saved_count = 0
        for paper in papers:
            try:
                self.repo.save_raw_paper(paper)
                saved_count += 1
            except Exception as e:
                pass
        
        print(f"âœ… OpenAlex {venue_name} {year}: å·²ä¿å­˜ {saved_count} ç¯‡")
        return saved_count
    
    # ========== Semantic Scholar é‡‡é›† ==========
    
    def ingest_s2_venue(
        self,
        venue_name: str,
        year: int,
        max_results: int = 1000,
    ) -> int:
        """æŒ‰ä¼šè®®é‡‡é›† Semantic Scholar è®ºæ–‡"""
        client = self._get_s2_client()
        
        print(f"\nğŸ“¥ [Ingestion] æ­£åœ¨ä» Semantic Scholar é‡‡é›† {venue_name} {year}...")
        
        raw_papers = client.search_papers(venue_name, year, max_results)
        
        saved_count = 0
        for data in raw_papers:
            try:
                paper = self._parse_s2_to_raw(data, venue_name, year)
                if paper:
                    self.repo.save_raw_paper(paper)
                    saved_count += 1
            except Exception as e:
                pass
        
        print(f"âœ… Semantic Scholar {venue_name} {year}: å·²ä¿å­˜ {saved_count} ç¯‡")
        return saved_count
    
    def _parse_s2_to_raw(self, data: Dict, venue: str, year: int) -> Optional[RawPaper]:
        """å°† S2 æ•°æ®è½¬æ¢ä¸º RawPaper"""
        try:
            paper_id = data.get("paperId", "")
            if not paper_id:
                return None
            
            authors = []
            for author in data.get("authors", []):
                if isinstance(author, dict):
                    name = author.get("name", "")
                    if name:
                        authors.append(name)
            
            return RawPaper(
                source="s2",
                source_paper_id=paper_id,
                title=data.get("title", ""),
                abstract=data.get("abstract", ""),
                authors=authors,
                year=year,
                venue_raw=venue,
                doi=None,
                raw_json=data,
                retrieved_at=datetime.now(),
            )
        except:
            return None
    
    # ========== OpenReview é‡‡é›† ==========
    
    def ingest_openreview_venue(
        self,
        venue_name: str,
        year: int,
        limit: int = None,
    ) -> int:
        """é‡‡é›† OpenReview ä¼šè®®è®ºæ–‡"""
        if venue_name not in VENUES:
            print(f"âš ï¸ æœªé…ç½®çš„ä¼šè®®: {venue_name}")
            return 0
        
        config = VENUES[venue_name]
        client = self._get_or_client()
        
        venue_id = config.venue_id_pattern.format(year=year)
        
        print(f"\nğŸ“¥ [Ingestion] æ­£åœ¨ä» OpenReview é‡‡é›† {venue_name} {year}...")
        
        saved_count = 0
        for note in client.get_accepted_papers(venue_id, limit=limit):
            try:
                paper = self._parse_or_to_raw(note, venue_name, year)
                if paper:
                    self.repo.save_raw_paper(paper)
                    saved_count += 1
            except Exception as e:
                pass
        
        print(f"âœ… OpenReview {venue_name} {year}: å·²ä¿å­˜ {saved_count} ç¯‡")
        return saved_count
    
    def _parse_or_to_raw(self, note, venue: str, year: int) -> Optional[RawPaper]:
        """å°† OpenReview Note è½¬æ¢ä¸º RawPaper"""
        try:
            content = note.content
            
            # è·å–æ ‡é¢˜
            title = content.get("title", {})
            if isinstance(title, dict):
                title = title.get("value", "")
            
            # è·å–æ‘˜è¦
            abstract = content.get("abstract", {})
            if isinstance(abstract, dict):
                abstract = abstract.get("value", "")
            
            # è·å–ä½œè€…
            authors = content.get("authors", {})
            if isinstance(authors, dict):
                authors = authors.get("value", [])
            if isinstance(authors, str):
                authors = [authors]
            
            # è·å–å…³é”®è¯ï¼ˆå­˜å…¥ commentsï¼‰
            keywords = content.get("keywords", {})
            if isinstance(keywords, dict):
                keywords = keywords.get("value", [])
            keywords_str = ",".join(keywords) if isinstance(keywords, list) else str(keywords)
            
            return RawPaper(
                source="openreview",
                source_paper_id=note.id,
                title=title,
                abstract=abstract,
                authors=authors if isinstance(authors, list) else [],
                year=year,
                venue_raw=venue,
                comments=keywords_str,  # å­˜å‚¨å…³é”®è¯
                raw_json={
                    "id": note.id,
                    "forum": getattr(note, "forum", None),
                    "content_keys": list(content.keys()),
                },
                retrieved_at=datetime.now(),
            )
        except Exception as e:
            print(f"è§£æ OpenReview note å¤±è´¥: {e}")
            return None
    
    # ========== æ‰¹é‡é‡‡é›† ==========
    
    def run(
        self,
        sources: List[str] = None,
        arxiv_days: int = 7,
        venues: List[str] = None,
        years: List[int] = None,
    ) -> Dict[str, int]:
        """
        è¿è¡Œå®Œæ•´é‡‡é›†æµç¨‹
        
        Args:
            sources: æ•°æ®æºåˆ—è¡¨ ["arxiv", "openalex", "s2", "openreview"]
            arxiv_days: arXiv é‡‡é›†å¤©æ•°
            venues: ä¼šè®®åˆ—è¡¨
            years: å¹´ä»½åˆ—è¡¨
            
        Returns:
            å„æ•°æ®æºé‡‡é›†æ•°é‡
        """
        sources = sources or ["arxiv", "openalex"]
        results = {}
        
        print("\n" + "=" * 60)
        print("ğŸ“¥ [Ingestion Agent] å¼€å§‹é‡‡é›†åŸå§‹æ•°æ®")
        print("=" * 60)
        
        # arXiv
        if "arxiv" in sources:
            results["arxiv"] = self.ingest_arxiv_recent(days=arxiv_days)
        
        # OpenAlex
        if "openalex" in sources and venues and years:
            count = 0
            for venue in venues:
                for year in years:
                    count += self.ingest_openalex_venue(venue, year)
            results["openalex"] = count
        
        # Semantic Scholar
        if "s2" in sources and venues and years:
            count = 0
            for venue in venues:
                for year in years:
                    count += self.ingest_s2_venue(venue, year)
            results["s2"] = count
        
        # OpenReview
        if "openreview" in sources:
            count = 0
            or_venues = venues or list(VENUES.keys())
            or_years = years or [2024, 2023]
            for venue in or_venues:
                if venue in VENUES:
                    for year in or_years:
                        if year in VENUES[venue].years:
                            count += self.ingest_openreview_venue(venue, year)
            results["openreview"] = count
        
        total = sum(results.values())
        print(f"\nğŸ“Š [Ingestion] æ€»è®¡é‡‡é›† {total} ç¯‡åˆ° Raw Layer")
        
        return results


def run_ingestion(
    sources: List[str] = None,
    arxiv_days: int = 7,
    venues: List[str] = None,
    years: List[int] = None,
) -> Dict[str, int]:
    """è¿è¡Œé‡‡é›†çš„ä¾¿æ·å‡½æ•°"""
    agent = IngestionAgent()
    return agent.run(
        sources=sources,
        arxiv_days=arxiv_days,
        venues=venues,
        years=years,
    )
